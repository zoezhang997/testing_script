{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edbf9cc9",
   "metadata": {},
   "source": [
    "Column removed: \n",
    "['str User Logon Name','Sales Date']\n",
    "\n",
    "Column is not matched:\n",
    "'StrIndex','str_First_Name','str_Last_Name','PAX_Rev','BookedPAX','ValidPAX','Airport_CheckedIn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "094a3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from get_secret import get_secret\n",
    "import snowflake.connector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67dcc2",
   "metadata": {},
   "source": [
    "# Import and clean snowflake views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f36305d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Snowflake connection parameters\n",
    "config_json = json.loads(get_secret())\n",
    "config_json.update({'warehouse':'COMPUTE_WH', 'database':'ANALYTICS_PROD','schema': 'IOATAWARE',\"loglevel\":'DEBUG'})\n",
    "\n",
    "# Create a connection object\n",
    "conn = snowflake.connector.connect(**config_json)\n",
    "# Create a cursor object to execute SQL queries\n",
    "cur = conn.cursor()\n",
    "# Execute a sample SQL query\n",
    "query = \"select * from ANALYTICS_PROD.IOATAWARE.VW_PAX_RAW_DATA where \\\"Flight Date\\\" ='08/01/2023' \"\n",
    "cur.execute(query)\n",
    "# Fetch the results\n",
    "results_df = cur.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f29f3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_pd_df = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "341838fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\619146900.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  snowflake_pd_df['dtm Local Dep Date'] = pd.to_datetime(snowflake_pd_df['dtm Local Dep Date'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\619146900.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  snowflake_pd_df['dtm DOB Date'] = pd.to_datetime(snowflake_pd_df['dtm DOB Date'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\619146900.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  snowflake_pd_df['Check In Time'] = pd.to_datetime(snowflake_pd_df['Check In Time'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\619146900.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  snowflake_pd_df['Board Time'] = pd.to_datetime(snowflake_pd_df['Board Time'])\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove = ['Valid PAX','str User Logon Name','Sales Date']\n",
    "snowflake_pd_df = snowflake_pd_df.drop(columns=columns_to_remove)\n",
    "\n",
    "# columns_to_process = ['Flight Date','Actual Flight Date','dtm Local Dep Dat','dtm Sked Local Dep Date','dtm DOB Date','Sales Date','dtm Last Mod Date','dtm Boarding Time','Check In Time','Board Time']\n",
    "\n",
    "# # Apply the function to specified columns in the dataframe\n",
    "# for col in columns_to_process:\n",
    "#     snowflake_pd_df[col] = snowflake_pd_df[col].apply(changetodate)\n",
    "#     print(col,\"finished\")\n",
    "    \n",
    "snowflake_pd_df['Flight Date'] = pd.to_datetime(snowflake_pd_df['Flight Date'])\n",
    "snowflake_pd_df['Actual Flight Date'] = pd.to_datetime(snowflake_pd_df['Actual Flight Date'])\n",
    "snowflake_pd_df['dtm Local Dep Date'] = pd.to_datetime(snowflake_pd_df['dtm Local Dep Date'])\n",
    "snowflake_pd_df['dtm Sked Local Dep Date'] = pd.to_datetime(snowflake_pd_df['dtm Sked Local Dep Date'])\n",
    "snowflake_pd_df['dtm DOB Date'] = pd.to_datetime(snowflake_pd_df['dtm DOB Date'])\n",
    "#snowflake_pd_df['Sales Date'] = pd.to_datetime(snowflake_pd_df['Sales Date'])\n",
    "snowflake_pd_df['dtm Last Mod Date'] = pd.to_datetime(snowflake_pd_df['dtm Last Mod Date'])\n",
    "snowflake_pd_df['dtm Boarding Time'] = pd.to_datetime(snowflake_pd_df['dtm Boarding Time'])\n",
    "snowflake_pd_df['Check In Time'] = pd.to_datetime(snowflake_pd_df['Check In Time'])\n",
    "snowflake_pd_df['Board Time'] = pd.to_datetime(snowflake_pd_df['Board Time'])\n",
    "\n",
    "snowflake_pd_df['str Flight Nmbr'].replace('', np.nan, inplace=True)\n",
    "snowflake_pd_df['str Flight Nmbr'] = snowflake_pd_df['str Flight Nmbr'].fillna(0)\n",
    "snowflake_pd_df['str Flight Nmbr'] = snowflake_pd_df['str Flight Nmbr'].astype(int)\n",
    "snowflake_pd_df['str Infant Pass Sequence Number'].replace('', np.nan, inplace=True)\n",
    "snowflake_pd_df['str Infant Pass Sequence Number'] = snowflake_pd_df['str Infant Pass Sequence Number'].fillna(0)\n",
    "snowflake_pd_df['str Infant Pass Sequence Number'] = snowflake_pd_df['str Infant Pass Sequence Number'].astype(float)\n",
    "snowflake_pd_df['Time Zone Adjustment'] = snowflake_pd_df['Time Zone Adjustment'].astype(float)\n",
    "\n",
    "# snowflake_pd_df['str City'].replace('', np.nan, inplace=True)\n",
    "# snowflake_pd_df['str Postal Code'].replace('', np.nan, inplace=True)\n",
    "\n",
    "snowflake_pd_df['str Special Needs'].replace('', np.nan, inplace=True)\n",
    "snowflake_pd_df['str Special Needs'] = snowflake_pd_df['str Special Needs'].fillna(0)\n",
    "snowflake_pd_df['str Special Needs'] = snowflake_pd_df['str Special Needs'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd211de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in snowflake_pd_df.columns:\n",
    "#     print(f\"{col}: {snowflake_pd_df[col].dtype}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040d98b",
   "metadata": {},
   "source": [
    "# Import and clean report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1d27d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\3231810684.py:1: DtypeWarning: Columns (46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  report_df = pd.read_csv('Pax_Raw_Data/PAX_Raw_Data_0801.csv', skiprows=0)\n"
     ]
    }
   ],
   "source": [
    "report_df = pd.read_csv('Pax_Raw_Data/PAX_Raw_Data_0801.csv', skiprows=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bcde455",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['ValidPAX','str_GeneralNumber1','SalesDate','str_GeneralNumber2',\n",
    "                     'str_Addr1','str_Addr2','str_User_Logon_Name']\n",
    "report_df = report_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2329ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\2508785233.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  report_df['dtm_Local_Dep_Date'] = pd.to_datetime(report_df['dtm_Local_Dep_Date'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\2508785233.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  report_df['dtm_Sked_Local_Dep_Date'] = pd.to_datetime(report_df['dtm_Sked_Local_Dep_Date'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\2508785233.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  report_df['dtm_DOB_Date'] = pd.to_datetime(report_df['dtm_DOB_Date'])\n",
      "C:\\Users\\Ruiying.Zhang\\AppData\\Local\\Temp\\ipykernel_80668\\2508785233.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  report_df['dtm_Boarding_Time'] = pd.to_datetime(report_df['dtm_Boarding_Time'])\n"
     ]
    }
   ],
   "source": [
    "report_df['FlightDate'] = pd.to_datetime(report_df['FlightDate'])\n",
    "report_df['ActualFlightDate'] = pd.to_datetime(report_df['ActualFlightDate'])\n",
    "report_df['dtm_Local_Dep_Date'] = pd.to_datetime(report_df['dtm_Local_Dep_Date'])\n",
    "report_df['dtm_Sked_Local_Dep_Date'] = pd.to_datetime(report_df['dtm_Sked_Local_Dep_Date'])\n",
    "report_df['dtm_DOB_Date'] = pd.to_datetime(report_df['dtm_DOB_Date'])\n",
    "#report_df['SalesDate'] = pd.to_datetime(report_df['SalesDate'])\n",
    "report_df['dtm_Last_Mod_Date'] = pd.to_datetime(report_df['dtm_Last_Mod_Date'])\n",
    "report_df['dtm_Boarding_Time'] = pd.to_datetime(report_df['dtm_Boarding_Time'])\n",
    "report_df['CheckInTime'] = pd.to_datetime(report_df['CheckInTime'])\n",
    "report_df['BoardTime'] = pd.to_datetime(report_df['BoardTime'])\n",
    "\n",
    "report_df['str_Infant_Pass_Sequence_Number']= report_df['str_Infant_Pass_Sequence_Number'].fillna(0)\n",
    "report_df['str_Special_Needs']= report_df['str_Special_Needs'].fillna(0)\n",
    "\n",
    "report_df['str_City']= report_df['str_City'].fillna('')\n",
    "report_df['str_Postal_Code'] = report_df['str_Postal_Code'].fillna('')\n",
    "\n",
    "\n",
    "report_df['TimeZoneAdjustment'] = report_df['TimeZoneAdjustment'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7ef0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in report_df.columns:\n",
    "#     print(f\"{col}: {report_df[col].dtype}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f05fe9",
   "metadata": {},
   "source": [
    "# Compare two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "691c6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_pd_df.columns = report_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f9d0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_pd_df =snowflake_pd_df.fillna('')\n",
    "report_df =report_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4725edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_df2_accuracy(df1, df2):\n",
    "    merged = df1.merge(df2, how = 'outer', indicator = True)\n",
    "    df1_only = merged[merged['_merge'] == \"left_only\"]\n",
    "    df2_only = merged[merged['_merge'] == \"right_only\"]\n",
    "\n",
    "\n",
    "    # Calculate accuracy as a percentage\n",
    "    accuracy_df1 = ((len(df1) - len(df1_only)) / len(df1)) * 100\n",
    "    accuracy_df2 = ((len(df2) - len(df2_only)) / len(df2)) * 100\n",
    "\n",
    "    return accuracy_df1,accuracy_df2,df1_only,df2_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adcc8a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 7.00% snowflake records in report\n",
      "The number of records in snowflake but not in report is 165997\n",
      "Accuracy: 65.24% report records in snowflake\n",
      "The number of records in report but not in snowflake is 5371\n"
     ]
    }
   ],
   "source": [
    "report_accuracy,snowflake_accuracy,report_only,snowflake_only = calculate_df2_accuracy(report_df,snowflake_pd_df)\n",
    "\n",
    "print(f\"Accuracy: {snowflake_accuracy:.2f}%\" \" snowflake records in report\\nThe number of records in snowflake but not in report is\", len(snowflake_only))\n",
    "print(f\"Accuracy: {report_accuracy:.2f}%\"\" report records in snowflake\\nThe number of records in report but not in snowflake is\", len(report_only))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d27906",
   "metadata": {},
   "source": [
    "# Output the difference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62792626",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    snowflake_only.to_csv(\"Pax_Raw_Data/snowflake_only_record.csv\", index=False) \n",
    "except:\n",
    "    print(\"No snowflake only records\")\n",
    "try:\n",
    "    report_only.to_csv(\"Pax_Raw_Data/report_only_record.csv\", index=False) \n",
    "except:\n",
    "    print(\"No report only records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e675204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
